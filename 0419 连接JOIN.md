# 前言

确实，JOIN操作还是蛮常用的操作，因为很多数据都是分布在多个数据框里面的。而且之前不是也有一个anti_join的操作在缺失值的部分嘛（虽然从来没听说过还能这样）。我最早知道这个操作还是在大一的大计基课上老师展示的。但是在R语言我记得有很多函数都能实现join的操作诶。不知道这里用的是什么方法，应该是dplyr。

[SQL 连接(JOIN)](https://www.runoob.com/sql/sql-join.html)

第二版和第一版比也出现了很多变化。但是基本上join需要实现的是这两个主要的功能

- 合并连接：向数据框中加入新变量，新变量的值是另一个数据框中的匹配观测。mutate
- 筛选连接：根据是否匹配另一个数据框中的观测，筛选数据框中的观测。filter

做好准备吧。

```R
library(tidyverse)
library(nycflights13)
```

# 键

最早知道这个东西应该是微软的那个Acess里面有一个字段是非常死板的。当我们知道了两个表的键之后才能连接两个表格。

## 主键和外键

这里有涉及数据库的属于了。每一个连接的操作都涉及主键和外键。

1. 主键就是唯一识别每个观测（记录）的变量
2. 复合键也是一起帮助标记观测的，如果一个变量不够的话。

在这个包里面有4个数据框

`airlines`包含carrier和其全称，`carrier`就是主键

```R
airlines
#> # A tibble: 16 × 2
#>   carrier name                    
#>   <chr>   <chr>                   
#> 1 9E      Endeavor Air Inc.       
#> 2 AA      American Airlines Inc.  
#> 3 AS      Alaska Airlines Inc.    
#> 4 B6      JetBlue Airways         
#> 5 DL      Delta Air Lines Inc.    
#> 6 EV      ExpressJet Airlines Inc.
#> # ℹ 10 more rows
```

`airports`记录的是机场的信息，`faa`就是主键，是机场的编码

```R
airports
#> # A tibble: 1,458 × 8
#>   faa   name                            lat   lon   alt    tz dst  
#>   <chr> <chr>                         <dbl> <dbl> <dbl> <dbl> <chr>
#> 1 04G   Lansdowne Airport              41.1 -80.6  1044    -5 A    
#> 2 06A   Moton Field Municipal Airport  32.5 -85.7   264    -6 A    
#> 3 06C   Schaumburg Regional            42.0 -88.1   801    -6 A    
#> 4 06N   Randall Airport                41.4 -74.4   523    -5 A    
#> 5 09J   Jekyll Island Airport          31.1 -81.4    11    -5 A    
#> 6 0A9   Elizabethton Municipal Airpo…  36.4 -82.2  1593    -5 A    
#> # ℹ 1,452 more rows
#> # ℹ 1 more variable: tzone <chr>
```

`planes`记录的是肺疾的信息，有`tailnum`航班信息，可以作为主键，以及后面的都是飞机的相关信息

```R
planes
#> # A tibble: 3,322 × 9
#>   tailnum  year type              manufacturer    model     engines
#>   <chr>   <int> <chr>             <chr>           <chr>       <int>
#> 1 N10156   2004 Fixed wing multi… EMBRAER         EMB-145XR       2
#> 2 N102UW   1998 Fixed wing multi… AIRBUS INDUSTR… A320-214        2
#> 3 N103US   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2
#> 4 N104UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2
#> 5 N10575   2002 Fixed wing multi… EMBRAER         EMB-145LR       2
#> 6 N105UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2
#> # ℹ 3,316 more rows
#> # ℹ 3 more variables: seats <int>, speed <int>, engine <chr>
```

`weather`是天气，可以通过`origin`和`time_hour`组合成为复合的主键。

```R
weather
#> # A tibble: 26,115 × 15
#>   origin  year month   day  hour  temp  dewp humid wind_dir
#>   <chr>  <int> <int> <int> <int> <dbl> <dbl> <dbl>    <dbl>
#> 1 EWR     2013     1     1     1  39.0  26.1  59.4      270
#> 2 EWR     2013     1     1     2  39.0  27.0  61.6      250
#> 3 EWR     2013     1     1     3  39.0  28.0  64.4      240
#> 4 EWR     2013     1     1     4  39.9  28.0  62.2      250
#> 5 EWR     2013     1     1     5  39.0  28.0  64.4      260
#> 6 EWR     2013     1     1     6  37.9  28.0  67.2      240
#> # ℹ 26,109 more rows
#> # ℹ 6 more variables: wind_speed <dbl>, wind_gust <dbl>, …
```

所谓的外键就是外部数据库和该数据库对应的变量。把flights作为外部数据库

- `flights$tailnum` 对应 `planes$tailnum`.
- `flights$carrier` 对应 `airlines$carrier`.
- `flights$origin` 对应 `airports$faa`.
- `flights$dest` 对应 `airports$faa`.
- `flights$origin`-`flights$time_hour` 对应 `weather$origin`-`weather$time_hour`.

作者还贴心的画了数据框之间的关联关系。

![The relationships between airports, planes, flights, weather, and airlines datasets from the nycflights13 package. airports$faa connected to the flights$origin and flights$dest. planes$tailnum is connected to the flights$tailnum. weather$time_hour and weather$origin are jointly connected to flights$time_hour and flights$origin. airlines$carrier is connected to flights$carrier. There are no direct connections between airports, planes, airlines, and weather data frames.](<./0419 连接JOIN.assets/relational.png>)

这些表格很不错，在不同表格中相同的东西都是用同一个名字命名的，这样就会很方便。唯一需要注意的一点，planes的year是生产日期，flights的year是出发日期。

## 检查主键

我们知道主键必须得是唯一标识，采用`count`和`filter`的方法看看有没有重复的主键。

> 话说进行连接主键不唯一我觉得也是可以接受吧。或者不用引入主键我觉得也没事吧。

```R
planes |> 
  count(tailnum) |> 
  filter(n > 1)
#> # A tibble: 0 × 2
#> # ℹ 2 variables: tailnum <chr>, n <int>

weather |> 
  count(time_hour, origin) |> 
  filter(n > 1)
#> # A tibble: 0 × 3
#> # ℹ 3 variables: time_hour <dttm>, origin <chr>, n <int>
```

很好，采用了复合键也就没有重复的了。与此同时，还要检查主键有没有缺失值（虽然缺失值一般不单个出现，但是上面的操作确实是会遗漏单个的`NA`对吧）

```R
planes |> 
  filter(is.na(tailnum))
#> # A tibble: 0 × 9
#> # ℹ 9 variables: tailnum <chr>, year <int>, type <chr>, manufacturer <chr>,
#> #   model <chr>, engines <int>, seats <int>, speed <int>, engine <chr>

weather |> 
  filter(is.na(time_hour) | is.na(origin))
#> # A tibble: 0 × 15
#> # ℹ 15 variables: origin <chr>, year <int>, month <int>, day <int>,
#> #   hour <int>, temp <dbl>, dewp <dbl>, humid <dbl>, wind_dir <dbl>, …
```

没有缺失值。

## 代理键

之前都在处理flights数据，没有涉及它的主键

```R
flights |> 
  count(time_hour, carrier, flight) |> 
  filter(n > 1)
#> # A tibble: 0 × 4
#> # ℹ 4 variables: time_hour <dttm>, carrier <chr>, flight <int>, n <int>
```

这样确实是可以实现复合主键不重复，但是比较容易混乱，不如直接写个数字序号不重复就好了。

```R
flights2 <- flights %>%
  mutate(id = row_number(), .before = 1)
flights2
```

在最前面一列加行名，即数字序号。这就是代理键。

## 练习

> We forgot to draw the relationship between `weather` and `airports` in [Figure 19.1](https://r4ds.hadley.nz/joins#fig-flights-relationships). What is the relationship and how should it appear in the diagram?

叫咱们发现天气和机场这两个数据集的关系，有点难啊。

```R
intersect(airports$faa,weather$origin)
flights$origin %>% unique()
#[1] "EWR" "LGA" "JFK"
```

虽然airports有很多，但是实际上weather和flights只用到了三个啊。怎么画我也不知道。不太了解数据库这个方向的知识。那应该就是origin到faa再画一个箭头吧。

> `weather` only contains information for the three origin airports in NYC. If it contained weather records for all airports in the USA, what additional connection would it make to `flights`?

这样dest也要算进去了。因为flights的dest是很多的。

> The `year`, `month`, `day`, `hour`, and `origin` variables almost form a compound key for `weather`, but there’s one hour that has duplicate observations. Can you figure out what’s special about that hour?

```R
weather %>%
      count(year, month, day,hour, origin) %>%
      filter(n > 1)
# A tibble: 3 x 6
   year month   day  hour origin     n
  <int> <int> <int> <int> <chr>  <int>
1  2013    11     3     1 EWR        2
2  2013    11     3     1 JFK        2
3  2013    11     3     1 LGA        2
```

同一个hour三个机场都出现了两个天气的记录。

```R
weather %>%
  filter(year == 2013, month == 11, day == 3, hour == 1) %>%
  view()
```

但是我看不出有什么东西啊，按照下面的是后来记录的，那么就是温度降低，湿度上升，风向改变了一点，西北往西打了一点。风速降低。整体气压偏低，但是气压升高。这样看来这个时候下雨了嘛？我好像看到2号的hour缺失值了。忘记看题目了，题目也说了，hour有什么特殊的，缺的就是2号的hour啊，这属于隐性缺失值，但是我忘记怎么补上了。为啥我用了complete还是没有补上呢？想半天想不出来啊。

```R
weather %>%
  complete(day, hour) %>%
  filter(year == 2013, month == 11, day %in% 2:3) %>%
  view()
```

> 我知道了，因为被我filter掉了，我虽然补上了hour和day，但是2013还是NA，其实这道题倒也不要求咱们补全。所以这个就是个插曲。

```R
full_time <- expand_grid(
  year = 2013,
  month = 11,
  day = 2,
  hour = 0:23
)

# 合并完整时间表和原始天气数据
weather_complete <- weather %>%
  filter(year == 2013, month == 11, day == 2) %>%
  right_join(full_time, by = c("year", "month", "day", "hour"))

# 查看结果
weather_complete %>%
  print(n = Inf)
```

chatgpt这种join确实也可以，但是为什么我那个不行呢？

> We know that some days of the year are special and fewer people than usual fly on them (e.g., Christmas eve and Christmas day). How might you represent that data as a data frame? What would be the primary key? How would it connect to the existing data frames?

这个就要设置一个节日表，主键就直接是节日名就好了，我就不相信会有重名的节日。后面跟着年、月、日的信息，和flights这个数据的年月日对上就好了。

> Draw a diagram illustrating the connections between the `Batting`, `People`, and `Salaries` data frames in the Lahman package. Draw another diagram that shows the relationship between `People`, `Managers`, `AwardsManagers`. How would you characterize the relationship between the `Batting`, `Pitching`, and `Fielding` data frames?

反正都是一样的列名，可以取个交集摸索一下。

```R
library(Lahman)
a <- colnames(Batting)
b <- colnames(People)
c <- colnames(Salaries)
r$> intersect(a,b)
[1] "playerID"

r$> intersect(a, c)
[1] "playerID" "yearID"   "teamID"   "lgID"

r$> intersect(b, c)
[1] "playerID"
```

然后咱们用obsidian的插件excalidraw试试。

![image-20240901165057539](<./0419 连接JOIN.assets/image-20240901165057539.png>)

大概就是这样？

![image-20240901165718009](<./0419 连接JOIN.assets/image-20240901165718009.png>)

说不定有遗漏呢

最后这个太复杂了，咱们还是，毕竟我也不懂棒球啊。好像Batting和Pitching一样的字段有很多。算了别纠结这些了。进入到下面的核心部分好了。

# 基本连接方式

## 合并连接

明明是合并，不知道为啥要叫做mutate啊，可呢个是增加了新的列，实现了mutate的效果吧。连接的效果就是通过键进行匹配，然后把另外一个数据框的内容复制到这个里面（当然还有很多细节不是吗）

缩小一下数据方便演示。

虽然有很多的join类的函数，但是最常用的的确是`left_join()`，这个的特点就是以我们不管加什么进去，得到的数据框和原本行数是一样的。

```R
flights2 <- flights |> 
  select(year, time_hour, origin, dest, tailnum, carrier)
flights2
#> # A tibble: 336,776 × 6
#>    year time_hour           origin dest  tailnum carrier
#>   <int> <dttm>              <chr>  <chr> <chr>   <chr>  
#> 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA     
#> 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA     
#> 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA     
#> 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6     
#> 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL     
#> 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA     
#> # ℹ 336,770 more rows
```

加入航空公司的名字，还是很智能的，自动识别一样的字段作为键值。

```r
flights2 |>
  left_join(airlines)
#> Joining with `by = join_by(carrier)`
#> # A tibble: 336,776 × 7
#>    year time_hour           origin dest  tailnum carrier name                
#>   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr>               
#> 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      United Air Lines In…
#> 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      United Air Lines In…
#> 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      American Airlines I…
#> 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      JetBlue Airways     
#> 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Delta Air Lines Inc.
#> 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      United Air Lines In…
#> # ℹ 336,770 more rows
```

加入天气的信息

```R
flights2 |> 
  left_join(weather |> select(origin, time_hour, temp, wind_speed))
#> Joining with `by = join_by(time_hour, origin)`
#> # A tibble: 336,776 × 8
#>    year time_hour           origin dest  tailnum carrier  temp wind_speed
#>   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <dbl>      <dbl>
#> 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA       39.0       12.7
#> 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA       39.9       15.0
#> 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA       39.0       15.0
#> 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6       39.0       15.0
#> 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL       39.9       16.1
#> 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA       39.0       12.7
#> # ℹ 336,770 more rows
```

加入飞机的参数。

```R
flights2 |> 
  left_join(planes |> select(tailnum, type, engines, seats))
#> Joining with `by = join_by(tailnum)`
#> # A tibble: 336,776 × 9
#>    year time_hour           origin dest  tailnum carrier type                
#>   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr>               
#> 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Fixed wing multi en…
#> 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      Fixed wing multi en…
#> 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Fixed wing multi en…
#> 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      Fixed wing multi en…
#> 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Fixed wing multi en…
#> 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Fixed wing multi en…
#> # ℹ 336,770 more rows
#> # ℹ 2 more variables: engines <int>, seats <int>
```

当`left_join()`在原本的里面有，外部来的没有，就只能填充上`NA`了。原本的没有，外面的有自然就不会匹配到了，`left_join`是不会加进来。估计这个时候就得用别的JOIN操作了。

```R
flights %>%
  filter(tailnum == "N3ALAA") %>%
  left_join(planes %>% select(tailnum, type, engines, seats))
any(flights$tailnum == "N3ALAA")
any(planes$tailnum == "N3ALAA")
```

## 指定连接的键

原来是这样，`left_join()`默认把两个数据框变量名的交集作为连接键，我说怎么这么智能呢。这个方式叫做自然连接。

但是一旦把flights2和planes连接在一起就会不对了，因为我们知道year对应的是不一样的，那对不上就都用NA补了。这里补的原因是外部没有匹配到合适的，因为默认把year和tailnum作为复合主键一起匹配了。

```r
flights2 |> 
  left_join(planes)
#> Joining with `by = join_by(year, tailnum)`
#> # A tibble: 336,776 × 13
#>    year time_hour           origin dest  tailnum carrier type  manufacturer
#>   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr> <chr>       
#> 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      <NA>  <NA>        
#> 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      <NA>  <NA>        
#> 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      <NA>  <NA>        
#> 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      <NA>  <NA>        
#> 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      <NA>  <NA>        
#> 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      <NA>  <NA>        
#> # ℹ 336,770 more rows
#> # ℹ 5 more variables: model <chr>, engines <int>, seats <int>, …
```

这就得单独指定tailnum作为键匹配，就是价格`join_by()`，里面写的是变量。

```R
flights2 |> 
  left_join(planes, join_by(tailnum))
#> # A tibble: 336,776 × 14
#>   year.x time_hour           origin dest  tailnum carrier year.y
#>    <int> <dttm>              <chr>  <chr> <chr>   <chr>    <int>
#> 1   2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA        1999
#> 2   2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA        1998
#> 3   2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA        1990
#> 4   2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6        2012
#> 5   2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL        1991
#> 6   2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA        2012
#> # ℹ 336,770 more rows
#> # ℹ 7 more variables: type <chr>, manufacturer <chr>, model <chr>, …
```

但是你看到这样为了区分两个不一样的year，就在后面分别加了x和y的后缀。当然也可以修改后缀，比方说这样。

```R
flights2 %>%
  left_join(planes, join_by(tailnum), suffix = c("", "_plane"))
```

那要是想把`flights2$dest`和`airports$faa`连接起来呢，虽然内容是一样的，但是名字不一样了，也匹配不到了。那就要加两个等号了。这就用到`left_join(...,join_by(原 == 外))`的写法，作为一种**equi join（等值连接）**的特点了

```R
flights2 |> 
  left_join(airports, join_by(dest == faa))
#> # A tibble: 336,776 × 13
#>    year time_hour           origin dest  tailnum carrier name                
#>   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr>               
#> 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      George Bush Interco…
#> 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      George Bush Interco…
#> 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Miami Intl          
#> 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      <NA>                
#> 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Hartsfield Jackson …
#> 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Chicago Ohare Intl  
#> # ℹ 336,770 more rows
#> # ℹ 6 more variables: lat <dbl>, lon <dbl>, alt <dbl>, tz <dbl>, …

flights2 |> 
  left_join(airports, join_by(origin == faa))
#> # A tibble: 336,776 × 13
#>    year time_hour           origin dest  tailnum carrier name               
#>   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr>              
#> 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Newark Liberty Intl
#> 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      La Guardia         
#> 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      John F Kennedy Intl
#> 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      John F Kennedy Intl
#> 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      La Guardia         
#> 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Newark Liberty Intl
#> # ℹ 336,770 more rows
#> # ℹ 6 more variables: lat <dbl>, lon <dbl>, alt <dbl>, tz <dbl>, …
```

当然还有别的写法，我也是经常用到，经常忘记，经常弄混，用的是字符串的写法。

- `by = "x"` 和`join_by(x)`等价
- `by = c("a" = "x")` 和 `join_by(a == x)`等价

一般是推荐`join_by()`，因为更加简洁，不需要写引号和combine。

像之前单纯的指定其实也是一种简写，实际上是`join_by(tail_num == tail_num)`这样就完全保留了等值连接的特点了。

还有剩下三种join函数。

`inner_join()` , `right_join()` , `full_join()` 差不多。

1. 左连接保留x所有行
2. 右连接保留y所有行
3. 全连接保留x和y所有行
4. 内连接保留x和y都出现的行

这些原理性质的之后再讲吧。

## 筛选连接

两种连接都是筛选连接，功能还有筛选行。

- 半连接`semi_join`，保留x在y中匹配的行
- 反连接`anti_join`，保留x在y中没出现的行

看看半连接，查询所有机场中出现在flights出发点中机场的信息

```R
airports |> 
  semi_join(flights2, join_by(faa == origin))
#> # A tibble: 3 × 8
#>   faa   name                  lat   lon   alt    tz dst   tzone           
#>   <chr> <chr>               <dbl> <dbl> <dbl> <dbl> <chr> <chr>           
#> 1 EWR   Newark Liberty Intl  40.7 -74.2    18    -5 A     America/New_York
#> 2 JFK   John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York
#> 3 LGA   La Guardia           40.8 -73.9    22    -5 A     America/New_York
```

你看输出结果并没有附上flights2的变量，果真是只有筛选作用啊。试想一下，不用join操作，那我要先取交集，然后再筛选行，属实是造轮子了。

反连接，看看有哪些机场是flights机场提到，但是在airports里面查询不到的。

```R
flights2 |> 
  anti_join(airports, join_by(dest == faa)) |> 
  distinct(dest)
#> # A tibble: 4 × 1
#>   dest 
#>   <chr>
#> 1 BQN  
#> 2 SJU  
#> 3 STT  
#> 4 PSE
```

## 练习

这一节设置的练习有点多有点耗费时间哦。

> Find the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the `weather` data. Can you see any patterns?

这里咱们还是用平均延误作为指标好了，以48小时作为单位，这个还蛮难的哦。有点像卷积的感觉。我感觉我得造轮子啊。

```R
my_flights <- flights %>%
  mutate(dep_time2 = make_datetime(year, month, day, dep_time %/% 100, dep_time %% 100))
my_flights
min(my_flights$dep_time2, na.rm = TRUE)
max(my_flights$dep_time2, na.rm = TRUE)
dep_delay_48h <- tibble(
  begin = seq(from = ymd_hms("2013-01-01 00:00:00"), to = ymd_hms("2014-01-01 00:00:00"), by = "1 hour"),
  end = begin + dhours(48),
  dep_delay = NA
)
for (i in 1:nrow(dep_delay_48h)) {
  dep_delay_48h$dep_delay[i] <- mean(my_flights$dep_delay[my_flights$dep_time2 >= dep_delay_48h$begin[i] & my_flights$dep_time2 < dep_delay_48h$end[i]], na.rm = TRUE)
}
dep_delay_48h %>%
  arrange(desc(dep_delay))
```

哈哈全程都用的base，还是base更好用啊哈哈哈哈。而且都是AI自己生成的，很符合我的心意。记下这个时间。

```R
# A tibble: 8,761 x 3
   begin               end                 dep_delay
   <dttm>              <dttm>                  <dbl>
 1 2013-03-07 12:00:00 2013-03-09 12:00:00      51.2
```

```R
weather %>%
  filter(time_hour >= ymd_hms("2013-03-07 12:00:00") & time_hour <= ymd_hms("2013-03-09 12:00:00")) %>%
  view()
```

大致看了一下，能见度很低嘛。

> Imagine you’ve found the top 10 most popular destinations using this code:
>
> ```R
> top_dest <- flights2 |>
>   count(dest, sort = TRUE) |>
>   head(10)
> ```
>
> How can you find all flights to those destinations?

```R
top_dest <- flights2 |>
  count(dest, sort = TRUE) |>
  head(10)
flights %>%
  left_join(top_dest)
```

这个还是比较简单的吧。

> Does every departing flight have corresponding weather data for that hour?

```R
flights %>%
  left_join(weather, join_by(year, month, day, hour, origin)) %>%
  filter(is.na(temp))
```

这种问题只要举出反例就好了。举出一堆NA即可。

> What do the tail numbers that don’t have a matching record in `planes` have in common? (Hint: one variable explains ~90% of the problems.)

虽说比较容易写，但是我确实没看出来什么共同点啊。

```R
flights %>%
  anti_join(planes, join_by(tailnum)) %>%
  distinct(tailnum,carrier) %>% 
  count(carrier)
```

莫非是AA和MQ特别多？

> Add a column to `planes` that lists every `carrier` that has flown that plane. You might expect that there’s an implicit relationship between plane and airline, because each plane is flown by a single airline. Confirm or reject this hypothesis using the tools you’ve learned in previous chapters.

```R
tc <- flights %>%
  distinct(tailnum, carrier) %>%
  arrange(tailnum) %>%
  group_by(tailnum) %>%
  mutate(carrier_all = paste(carrier, collapse = ","))

planes %>%
  left_join(tc, join_by(tailnum)) %>%
  filter(str_detect(carrier_all, ","))
```

大概就是这个意思，的确是有些飞机换过carrier。这里还用到了字符串呢。

> Add the latitude and the longitude of the origin *and* destination airport to `flights`. Is it easier to rename the columns before or after the join?

感觉还是连接前就重命名比较好，因为这里涉及两遍合并连接。

```R
flights %>%
  left_join(airports %>% select(faa, origin_lat = lat, origin_lon = lon), join_by(origin == faa)) %>%
  left_join(airports %>% select(faa, dest_lat = lat, dest_lon = lon), join_by(dest == faa))
```

写的很长的，所幸select的时候就可以改名字。不然弄成后缀了的话感觉要是知道我觉得其实也没事，这样看起来更简洁，虽然行数变多了。再用rename函数也不错对吧。但是本来就要select的呀。

> Compute the average delay by destination, then join on the `airports` data frame so you can show the spatial distribution of delays. Here’s an easy way to draw a map of the United States:
>
> ```r
> airports |>
>   semi_join(flights, join_by(faa == dest)) |>
>   ggplot(aes(x = lon, y = lat)) +
>     borders("state") +
>     geom_point() +
>     coord_quickmap()
> ```
>
> You might want to use the `size` or `color` of the points to display the average delay for each airport.

这道题给了画美国地图的方法，但是不知道用哪个延误，既然是目的地，那还是用arr_delay好了。稍微修改一下，加一个`left_join`插入延误数据就好了。我没看到下面的提示，没想到也是不谋而合。

```R
avg_delay_dest <- flights %>%
  group_by(dest) %>%
  summarise(avg_arr_delay = mean(arr_delay, na.rm = TRUE))

airports |>
  semi_join(flights, join_by(faa == dest)) |>
  left_join(avg_delay_dest, join_by(faa == dest)) %>%
  ggplot(aes(x = lon, y = lat)) +
  borders("state") +
  geom_point(aes(size = avg_arr_delay, color = avg_arr_delay)) +
  coord_quickmap() +
  scale_color_gradient(low = "white", high = "red")
```

![目的地延误地图](<./0419 连接JOIN.assets/目的地延误地图.png>)

> What happened on June 13 2013? Draw a map of the delays, and then use Google to cross-reference with the weather.

```R
avg_delay_dest_20230613 <- flights %>%
  filter(year == 2013, month == 6, day == 13) %>%
  group_by(dest) %>%
  summarise(avg_arr_delay = mean(arr_delay, na.rm = TRUE))

airports |>
  semi_join(flights, join_by(faa == dest)) |>
  left_join(avg_delay_dest_20230613, join_by(faa == dest)) %>%
  ggplot(aes(x = lon, y = lat)) +
  borders("state") +
  geom_point(aes(size = avg_arr_delay, color = avg_arr_delay)) +
  coord_quickmap() +
  scale_color_gradient(low = "white", high = "red")
```

![目的地延误地图20130613](<./0419 连接JOIN.assets/目的地延误地图20130613.png>)反正也只能问chatgpt咯

https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-june-2013

这种数据都能搜到，我是没有打开看哦。

# 连接的原理

这是解释各种JOIN操作的原理的，为啥不先讲啊。不过只有用到了才会思考这么做的用处吧。

这里没有啥代码，主要就是演示

```R
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     3, "x3"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     4, "y3"
)
```

生成了两个数据框

![x and y are two data frames with 2 columns and 3 rows, with contents as described in the text. The values of the keys are colored: 1 is green, 2 is purple, 3 is orange, and 4 is yellow.](<./0419 连接JOIN.assets/setup.png>)

所谓的内连接就是就是找到x和y键值都存在的，也就是交集![x and y are placed at right-angles with lines forming a grid of potential matches. Keys 1 and 2 appear in both x and y, so we get a match, indicated by a dot. Each dot corresponds to a row in the output, so the resulting joined data frame has two rows.](<./0419 连接JOIN.assets/inner.png>)

左连接就是保留x有，y没有的就用NA替代。

![Compared to the previous diagram showing an inner join, the y table gets a new virtual row containin NA that will match any row in x that didn't otherwise match. This means that the output now has three rows. For key = 3, which matches this virtual row, val_y takes value NA.](<./0419 连接JOIN.assets/left.png>)

右连接则相反，保留y轴所有的，遇到x没有的就用NA替代。![Compared to the previous diagram showing an left join, the x table now gains a virtual row so that every row in y gets a match in x. val_x contains NA for the row in y that didn't match x.](<./0419 连接JOIN.assets/right.png>)

全连接就是保留x和y都有的，谁也别落下。

![Now both x and y have a virtual row that always matches. The result has 4 rows: keys 1, 2, 3, and 4 with all values from val_x and val_y, however key 2, val_y and key 4, val_x are NAs since those keys don't have a match in the other data frames.](<./0419 连接JOIN.assets/full.png>)

另外一种呈现方式就是韦恩图了

![Venn diagrams for inner, full, left, and right joins. Each join represented with two intersecting circles representing data frames x and y, with x on the right and y on the left. Shading indicates the result of the join.](<./0419 连接JOIN.assets/venn.png>)

上面这些都叫等值连接（你不是叫mutate连接吗哈哈），意思就是说行和匹配一致的意思吧。

## 行匹配

前面都是有或没有的情况，无非0或1。但是我常常会看到一些键值重复的情况，那这种情况可咋办捏？（这里应该不能叫键值了，或许叫匹配项比较好我觉得，因为我一直以为键值就是唯一的）

那这个时候就会把所有重复的都留下，然后自身复制，而不是只选一个。![A join diagram where x has key values 1, 2, and 3, and y has key values 1, 2, 2. The output has three rows because key 1 matches one row, key 2 matches two rows, and key 3 matches zero rows.](<./0419 连接JOIN.assets/match-types.png>)

写个代码试试

```R
r$> right_join(x, y, by = "key")
# A tibble: 3 x 3
    key val_x val_y
  <dbl> <chr> <chr>
1     1 x1    y1
2     2 x2    y2
3     2 x2    y3

      1, "x1",
      2, "x2",
      3, "x3"
    )
    y <- tribble(
      ~key, ~val_y,
      1, "y1",
      2, "y2",
      2, "y3"
    )
    left_join(x, y, by = "key")
# A tibble: 4 x 3
    key val_x val_y
  <dbl> <chr> <chr>
1     1 x1    y1
2     2 x2    y2
3     2 x2    y3
4     3 x3    NA
```

那要是x和y都有重复的键呢？还是会交叉重复

```r
df1 <- tibble(key = c(1, 2, 2), val_x = c("x1", "x2", "x3"))
df2 <- tibble(key = c(1, 2, 2), val_y = c("y1", "y2", "y3"))
inner_join(df1, df2, by = "key")
left_join(df1, df2, by = "key")
#> Warning in inner_join(df1, df2, join_by(key)): Detected an unexpected many-to-many relationship between `x` and `y`.
#> ℹ Row 2 of `x` matches multiple rows in `y`.
#> ℹ Row 2 of `y` matches multiple rows in `x`.
#> ℹ If a many-to-many relationship is expected, set `relationship =
#>   "many-to-many"` to silence this warning.
#> # A tibble: 5 × 3
#>     key val_x val_y
#>   <dbl> <chr> <chr>
#> 1     1 x1    y1   
#> 2     2 x2    y2   
#> 3     2 x2    y3   
#> 4     2 x3    y2   
#> 5     2 x3    y3
left_join(df1, df2, by = "key",relationship = "many-to-many")
```

这个时候我觉得其实都没差。如果你不想要警报，那也可以设置。

## 筛选连接

这些个操作是不会给原数据添加新的列的，因为主要的目的还是筛选。只不过筛选的条件这次不是逻辑了，而是有没有。（以前都用`%in%`造轮子，不也是逻辑向量吗）

![A join diagram with old friends x and y. In a semi join, only the presence of a match matters so the output contains the same columns as x.](<./0419 连接JOIN.assets/semi.png>)

半连接保留另一个表里也有的

![An anti-join is the inverse of a semi-join so matches are drawn with red lines indicating that they will be dropped from the output.](<./0419 连接JOIN.assets/anti.png>)

反连接删除另一个表也有的，或者说保留另一个表没有的。

# 非等值连接

```r
x |> inner_join(y, join_by(key == key))
```

这是等值连接实际的全长写法。咱们也可以保留两列键值，这种形式在等值连接不常用，因为都一样，保留一列即可。但是这个keep参数也就等值才能用，非等值不用这个参数也会展示两列键值。

```R
x |> inner_join(y, join_by(key == key), keep = TRUE)
#> # A tibble: 2 × 4
#>   key.x val_x key.y val_y
#>   <dbl> <chr> <dbl> <chr>
#> 1     1 x1        1 y1   
#> 2     2 x2        2 y2
```

但是在非等值连接当中，保留两列键值是比较直观的。

```R
x %>% inner_join(y,join_by(key >= key))
# A tibble: 6 x 4
  key.x val_x key.y val_y
  <dbl> <chr> <dbl> <chr>
1     1 x1        1 y1
2     2 x2        1 y1
3     2 x2        2 y2
4     3 x3        1 y1
5     3 x3        2 y2
6     3 x3        3 y3  
```

![A join diagram illustrating join_by(key >= key). The first row of x matches one row of y and the second and thirds rows each match two rows. This means the output has five rows containing each of the following (key.x, key.y) pairs: (1, 1), (2, 1), (2, 2), (3, 1), (3, 2).](<./0419 连接JOIN.assets/gte.png>)

现在我知道了，原来也是逻辑形式进行匹配的。

> 非等值连接这个术语不好使，因为告诉咱们不是什么，而不是他是什么。
>
> 非等值居然还有四种啊。

1. **Cross joins**：交叉连接会匹配每一行与另一表中的每一行，生成所有可能的行对组合。例如，如果有两个表A和B，A有n行，B有m行，那么交叉连接的结果将有n*m行。
2. **Inequality joins**：不等连接使用小于(<)、小于等于(<=)、大于(>)和大于等于(>=)这些不等式操作符，而不是等式(==)。这种连接用于查找满足特定条件的行对，例如，找出所有价格低于某个值的商品。
3. **Rolling joins**：滚动连接类似于不等连接，但它只寻找最接近的匹配。这意味着它在查找匹配时会考虑距离或顺序，通常用于时间序列数据，以找到最接近的时间点。
4. **Overlap joins**：重叠连接是一种特殊的不等连接，它专门用于处理范围。这种连接用于查找两个范围之间有重叠部分的行对，例如，找出所有时间重叠的会议安排。

## 交叉连接

就是`cross_join()`，会生成一个叫笛卡尔集的东西，行数是两个数据表行的积。

![A join diagram showing a dot for every combination of x and y.](<./0419 连接JOIN.assets/cross.png>)

```R
df <- tibble(name = c("John", "Simon", "Tracy", "Max"))
df |> cross_join(df)
#> # A tibble: 16 × 2
#>   name.x name.y
#>   <chr>  <chr> 
#> 1 John   John  
#> 2 John   Simon 
#> 3 John   Tracy 
#> 4 John   Max   
#> 5 Simon  John  
#> 6 Simon  Simon 
#> # ℹ 10 more rows
```

这样名字就两两配对了。（有点像自己的关联矩阵的邻接表的形式）这个又有点像拿球，排列题目

## 不等连接

就是用`<`, `<=`, `>=`, or `>`这四种不等号连接两列键值。这个就没有专门的函数了，直接用inner_join()。那么我觉得其他等值连接肯定也是能用的，但是那样就比较复杂了。

```R
df <- tibble(id = 1:4, name = c("John", "Simon", "Tracy", "Max"))

df |> inner_join(df, join_by(id < id))
#> # A tibble: 6 × 4
#>    id.x name.x  id.y name.y
#>   <int> <chr>  <int> <chr> 
#> 1     1 John       2 Simon 
#> 2     1 John       3 Tracy 
#> 3     1 John       4 Max   
#> 4     2 Simon      3 Tracy 
#> 5     2 Simon      4 Max   
#> 6     3 Tracy      4 Max
```

这就产生了两两组合，类似于乒乓球比赛对吧。

## 滚动连接

用法是在`join_by()`里面，不等式外面套用`closest()`（最接近的，不是衣柜）。是一种特殊的不等连接，但是每次匹配只会取符合条件的最接近的行。

```R
df1 <- tibble(key = c(1, 2, 3), val_x = c("x1", "x2", "x3"))
df2 <- tibble(key = c(1, 2, 4), val_y = c("y1", "y2", "y4"))
inner_join(df1, df2, join_by(closest(key <= key)))
# A tibble: 3 x 4
  key.x val_x key.y val_y
  <dbl> <chr> <dbl> <chr>
1     1 x1        1 y1   
2     2 x2        2 y2   
3     3 x3        4 y4   
```

不会是作者画错了吧

![A rolling join is a subset of an inequality join so some matches are grayed out indicating that they're not used because they're not the "closest".](<./0419 连接JOIN.assets/closest.png>)

这里作者举了个例子，我感觉我都有点没看懂啊。

```R
parties <- tibble(
  q = 1:4,
  party = ymd(c("2022-01-10", "2022-04-04", "2022-07-11", "2022-10-03"))
)
set.seed(123)
employees <- tibble(
  name = sample(babynames::babynames$name, 100),
  birthday = ymd("2022-01-01") + (sample(365, 100, replace = TRUE) - 1)
)
employees
employees %>%
  left_join(parties, join_by(closest(birthday >= party)))
#> # A tibble: 100 × 4
#>   name     birthday       q party     
#>   <chr>    <date>     <int> <date>    
#> 1 Kemba    2022-01-22     1 2022-01-10
#> 2 Orean    2022-06-26     2 2022-04-04
#> 3 Kirstyn  2022-02-11     1 2022-01-10
#> 4 Amparo   2022-11-11     4 2022-10-03
#> 5 Belen    2022-03-25     1 2022-01-10
#> 6 Rayshaun 2022-01-11     1 2022-01-10
#> # ℹ 94 more rows
```

从结果来看应该是找到生日前的最后一次party吧。作者为啥说是生日之后的第一个？

但是不知道为什么这样子计算会产生两个缺失值。那当然咯，left_join会保留所有员工的生日，但是这两个日期都比最小的party还小，不符合大于等于，自然就用NA保留了。

```R
r$> employees %>%
      left_join(parties, join_by(closest(birthday >= party))) %>%
      arrange(birthday)
# A tibble: 100 x 4
   name      birthday       q party     
   <chr>     <date>     <int> <date>    
 1 Nalani    2022-01-04    NA NA        
 2 Maks      2022-01-07    NA NA        
 3 Li        2022-01-10     1 2022-01-10
```

据说可以用重叠连接overlap join操作。

## 重叠连接

和`closest()`的滚动连接类似，也是写在`join_by()`里面。但是有三种形态。

- `between(x, y_lower, y_upper)` 表示 `x >= y_lower, x <= y_upper`.
- `within(x_lower, x_upper, y_lower, y_upper)` 表示 `x_lower >= y_lower, x_upper <= y_upper`.
- `overlaps(x_lower, x_upper, y_lower, y_upper)` 表示 `x_lower <= y_upper, x_upper >= y_lower`.

> 理解起来还是需要一定的时间的， 而且我现在还不知道前两个区别是什么，难道是可以填1个或2两个的区别吗。

这次把party变成一个时间范围了。

```R
parties <- tibble(
  q = 1:4,
  party = ymd(c("2022-01-10", "2022-04-04", "2022-07-11", "2022-10-03")),
  start = ymd(c("2022-01-01", "2022-04-04", "2022-07-11", "2022-10-03")),
  end = ymd(c("2022-04-03", "2022-07-11", "2022-10-02", "2022-12-31"))
)
parties
#> # A tibble: 4 × 4
#>       q party      start      end       
#>   <int> <date>     <date>     <date>    
#> 1     1 2022-01-10 2022-01-01 2022-04-03
#> 2     2 2022-04-04 2022-04-04 2022-07-11
#> 3     3 2022-07-11 2022-07-11 2022-10-02
#> 4     4 2022-10-03 2022-10-03 2022-12-31
```

然后检查每个时间范围之间有没有重合，用来检查数据录入有没有问题。（作者还打趣地说自己录入很差）

```R
parties %>%
  inner_join(parties, join_by(overlaps(start, end, start, end), q < q)) %>%
  select(start.x,end.x,start.y,end.y)
#> # A tibble: 1 × 4
#>   start.x    end.x      start.y    end.y     
#>   <date>     <date>     <date>     <date>    
#> 1 2022-04-04 2022-07-11 2022-07-11 2022-10-02
```

这个例子里确实是有重合的，因为这个函数默认都是不等号带等号的。注意这里join_by里面竟然有两种，一个是重叠连接，一个是不等连接，意思是取组合就好了吧。放这个，就会多出四行，因为自己确实是完全和自己重合，不如上三角矩阵的匹配呢。

发现了重合之后重新输入时间范围

```R
parties <- tibble(
  q = 1:4,
  party = ymd(c("2022-01-10", "2022-04-04", "2022-07-11", "2022-10-03")),
  start = ymd(c("2022-01-01", "2022-04-04", "2022-07-11", "2022-10-03")),
  end = ymd(c("2022-04-03", "2022-07-10", "2022-10-02", "2022-12-31"))
)
```

```R
employees |> 
  inner_join(parties, join_by(between(birthday, start, end)), unmatched = "error")
#> # A tibble: 100 × 6
#>   name     birthday       q party      start      end       
#>   <chr>    <date>     <int> <date>     <date>     <date>    
#> 1 Kemba    2022-01-22     1 2022-01-10 2022-01-01 2022-04-03
#> 2 Orean    2022-06-26     2 2022-04-04 2022-04-04 2022-07-10
#> 3 Kirstyn  2022-02-11     1 2022-01-10 2022-01-01 2022-04-03
#> 4 Amparo   2022-11-11     4 2022-10-03 2022-10-03 2022-12-31
#> 5 Belen    2022-03-25     1 2022-01-10 2022-01-01 2022-04-03
#> 6 Rayshaun 2022-01-11     1 2022-01-10 2022-01-01 2022-04-03
#> # ℹ 94 more rows
```

因为这一次的条件是处于时间范畴之内，所以之前那个不行的也有对应的了。记得要在派对上庆祝他们的生日。

> 确实是不知道这里unmatched是干嘛的，有一个参数是na_matched。

## 练习

> Can you explain what’s happening with the keys in this equi join? Why are they different?
>
> ```R
> x |> full_join(y, join_by(key == key))
> #> # A tibble: 4 × 3
> #>     key val_x val_y
> #>   <dbl> <chr> <chr>
> #> 1     1 x1    y1   
> #> 2     2 x2    y2   
> #> 3     3 x3    <NA> 
> #> 4     4 <NA>  y3
> 
> x |> full_join(y, join_by(key == key), keep = TRUE)
> #> # A tibble: 4 × 4
> #>   key.x val_x key.y val_y
> #>   <dbl> <chr> <dbl> <chr>
> #> 1     1 x1        1 y1   
> #> 2     2 x2        2 y2   
> #> 3     3 x3       NA <NA> 
> #> 4    NA <NA>      4 y3
> ```

这道题也不知道在说什么。这是等值连接中的全连接，会保留x和y中的全部行。匹配的行就复制了。不匹配的就用NA补上。不一样的就是第二个把两个键值都保留了。其实没必要。不然叫什么等值连接呢。

> When finding if any party period overlapped with another party period we used `q < q` in the `join_by()`? Why? What happens if you remove this inequality?

这个我探索过了，也解释过了。删掉就会把自己和自己匹配的四行展示出来。因为自己和自己必然是重叠的。

# 总结

这里倒是神奇的一句也没有提到SQL哦。要是想了解数据库操作，那肯定就要了解SQL的语法了。那JOIN等操作又要重新学习了。（反而是coalesce还提到了SQL）。而且还没有推荐SQL的相关学习材料。估计是竞争关系哈哈。

到了这里就把这个数据转换部分学完了。发觉后面还有很复杂的三个部分，都是进阶操作呀。只能说再接再励呗。

下一章节就是数据导入了。顺序有点乱哦。一般来说这个应该是在数据结构教完之后再教的。但是这本书其实已经演变为进阶手册了，那这么设置我觉得也蛮好。

