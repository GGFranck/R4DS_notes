我也没想到这一章有这么多内容。

可以说这章的很多内容我应该都自己试验过，总感觉有的时候数据导入就是个玄学，多试试不同的方法，总有一种是适合的。

# 从文件读取数据

## 实践建议

tidyverse用的函数是 `read_csv`，和baseR就差了一个点。但是感觉本质还是不太一样的。tidyverse有的时候会高级一点，有的时候可能又会笨一点。但是有一个优势就是tidy风格是有读取后的反馈的，虽然看不懂。

```R
students <- read_csv("https://pos.it/r4ds-students-csv")
```

竟然还能读取网络的文件。我试了一下`read.csv`，一直在读取，但是就是不出来，就当做不能实现这样的功能吧。

![image-20240805110709966](<./0207 数据导入.assets/image-20240805110709966.png>)

> 其实这样写会默认把空字符串 `''` 改为NA

但是看到了不整洁的部分。在以前我得这么写

```r
data[data==''] <- NA
```

但是现在有了更好的选择。

```R
students <- read_csv('./students.csv',na = 'N/A');students
#这样写把默认的丢失了
students <- read_csv('./students.csv',na = c('N/A',''));students
#这样就对了
```

然后我也发现了，列名带有反引号，是因为列名当中带有空格， 之后作为变量就会比较麻烦，所以也需要整洁一下，更符合代码的规范。

当然也可以用一个之前被忘掉的包，确实已经被忘了，但是确实是很方便。

```r
students %>% rename(student_id = `Student ID`,
                    full_name = `Full Name`)
students %>% janitor::clean_names()
```

最后age这个也很乱啊，怎么还有five啊。这个其实就不是很好处理了。他是这么处理的，倒是也确实是tidyverse里面的函数`if_else()`。这个应该是属于向量化操作的一个。

```R
students <- students |>
  janitor::clean_names() |>
  mutate(
    meal_plan = factor(meal_plan),
    age = parse_number(if_else(age == "five", "5", age))
  )
```

这个`parse_number`在这里的作用是将字符串转换为数字，并不是真的取字符串第一个数字的意思（不是第一位数字）

```R
> parse_number('12a3')
[1] 12
```

> 这个部分虽然是教怎么导入数据，但是实际上教的却是数据刚导入后的简单处理。

## 其他参数

神奇了，这个`read_csv`还有这样神奇的功能。

```R
read_csv(
  "a,b,c
  1,2,3
  4,5,6"
)
#> # A tibble: 2 × 3
#>       a     b     c
#>   <dbl> <dbl> <dbl>
#> 1     1     2     3
#> 2     4     5     6
```

还可以跳过多行字符串的表头信息或者注释行。这对于咱们理解csv很有帮助，因为本身csv就是这样的多行的文本。所以即使不是字符串，是一个文件，这些方法肯定也是适用的。

```R
read_csv(
  "The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3",
  skip = 2
)
#> # A tibble: 1 × 3
#>       x     y     z
#>   <dbl> <dbl> <dbl>
#> 1     1     2     3
```
```R
read_csv(
  "# A comment I want to skip
  x,y,z
  1,2,3",
  comment = "#"
)
#> # A tibble: 1 × 3
#>       x     y     z
#>   <dbl> <dbl> <dbl>
#> 1     1     2     3
```

顺带一提的是`read_csv`会默认把第一行当做表头

```R
read_csv(
  "1,2,3
  4,5,6",
  col_names = FALSE
)
#> # A tibble: 2 × 3
#>      X1    X2    X3
#>   <dbl> <dbl> <dbl>
#> 1     1     2     3
#> 2     4     5     6
```

也可以自己设定表头。

```r
read_csv(
  "1,2,3
  4,5,6",
  col_names = c("x", "y", "z")
)
#> # A tibble: 2 × 3
#>       x     y     z
#>   <dbl> <dbl> <dbl>
#> 1     1     2     3
#> 2     4     5     6
```

## 其他文件读取

1. read_csv2()：这个函数用来读取使用分号(;)作为字段分隔符的文件。在一些国家，分号被用作小数点的标记，而逗号(,)则用来分隔字段。因此，这个函数适用于那些使用逗号作为小数点的国家的数据文件。
2. read_tsv()：这个函数用于读取制表符(\t)分隔的文件，通常称为制表分隔值文件(TSV)。
3. read_delim()：这个函数可以读取任何分隔符的文件。如果你没有指定分隔符，它会尝试自动猜测分隔符。
4. read_fwf()：这个函数用于读取固定宽度字段的文件。你可以通过fwf_widths()指定字段的宽度，或者通过fwf_positions()指定字段的位置。
5. read_table()：这个函数读取一种常见的固定宽度文件，其中列通过空白（如空格或制表符）来分隔。
6. read_log()：这个函数用于读取Apache风格的日志文件。

现在我终于了解了这些不同读取函数的区别。原来csv是逗号comma的英文打头的，tsv则是Tab制表符的意思。delim就自动，fwf不知道咋用，table会害怕表头中带有空格的，因为任意空格都有意义。

## 练习

> What function would you use to read a file where fields were separated with “|”?

```r
read_delim(
  'a|b|c
  1|2|3
  4|5|6'
)
# A tibble: 2 × 3
  a         b     c
  <chr> <dbl> <dbl>
1 "  1"     2     3
2 "  4"     5     6
```

感觉好像没有read.csv()好使诶，还是有缺陷啊。这里是真的要用parse处理a列了。

> Apart from `file`, `skip`, and `comment`, what other arguments do `read_csv()` and `read_tsv()` have in common?

```r
read_csv(
  file,
  col_names = TRUE,
  col_types = NULL,
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  guess_max = min(1000, n_max),
  name_repair = "unique",
  num_threads = readr_threads(),
  progress = show_progress(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)
```

除了  progress = show_progress(),这句

```r
read_tsv(
  file,
  col_names = TRUE,
  col_types = NULL,
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  guess_max = min(1000, n_max),
  progress = show_progress(),
  name_repair = "unique",
  num_threads = readr_threads(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)
```

> Sometimes strings in a CSV file contain commas. To prevent them from causing problems, they need to be surrounded by a quoting character, like `"` or `'`. By default, `read_csv()` assumes that the quoting character will be `"`. To read the following text into a data frame, what argument to `read_csv()` do you need to specify?

这个现在不需要指定参数就能运行

```R
read_csv("x,y\n1,'a,b'")
# A tibble: 1 × 2
      x y    
  <dbl> <chr>
1     1 'a,b'
```

> Identify what is wrong with each of the following inline CSV files. What happens when you run the code?

```R
read_csv("a,b\n1,2,3\n4,5,6")
read_csv("a,b,c\n1,2\n1,2,3,4")
read_csv("a,b\n\"1")
read_csv("a,b\n1,2\na,b")
read_csv("a;b\n1;3")
```

第一个就很神奇。原来不是叫咱们改错

- 第一个缺少一个列，2和3就会合在一起。
- 第二个少一个又多一个。
- 第三个就更神奇了，反斜杠加入之后竟然不产生任何问题。
- 第四个第一行是变量，第三行是字符串
- 第五个就不说了，分号不具有任何分隔作用

> Practice referring to non-syntactic names in the following data frame by:
>
> 1. Extracting the variable called `1`.
> 2. Plotting a scatterplot of `1` vs. `2`.
> 3. Creating a new column called `3`, which is `2` divided by `1`.
> 4. Renaming the columns to `one`, `two`, and `three`.

```R
annoying <- tibble(
  `1` = 1:10,
  `2` = `1` * 2 + rnorm(length(`1`))
)
```

这个就更有意思了。直接变量名就叫烦恼。就是说你用一个不符合语法规范的变量名会导致后面引用的时候非常麻烦。我有的时候就喜欢麻烦的，因为我很笨。

第一个就还好，因为select支持下标。

```R
annoying %>% select(1)
annoying %>% select(`1`)
```

但是第二个就必须加反引号了

```R
ggplot(annoying,aes(x = `1`,y = `2`))+
  geom_point()
```

不然就只会画出(1,2)这个点了。

```R
annoying %>% mutate(`3` = `2`/`1`)
```

这个也是

```R
annoying %>% rename(one = `1`,
                    two = `2`)
```

这样才舒服了。

如果用`janitor::clean_names()`就会变成`x1`，`x2`。总之他也会认为这样子不是很合法。

# 控制列的类型

## 猜测类型

这个我每次都感觉很麻烦，之前在baseR里面都是一个个修改的，那就只能复制粘贴了。不知道tidyR里面有没有什么简单一点的方法。

1. **逻辑值判断**：如果一个数据只包含'F', 'T', 'FALSE', 或者 'TRUE'（不区分大小写），那么这个数据被识别为逻辑值。逻辑值通常用来表示真或假。
2. **数值判断**：如果一个数据只包含数字，例如'1', '-4.5', '5e6'（科学记数法表示5乘以10的6次方），或者'Inf'（表示无穷大），那么这个数据被识别为数值。
3. **日期或日期时间判断**：如果一个数据符合ISO8601标准，那么这个数据被识别为日期或日期时间。ISO8601是一个国际标准，用于统一日期和时间的表示方法。例如，2024年8月5日可以表示为"2024-08-05"。
4. **字符串判断**：如果一个数据不符合以上任何一种情况，那么它将被识别为字符串。字符串是由字符组成的序列，可以包含任何字符，包括字母、数字、符号等。

原来会经历4个过程。

## 缺失值、列类型、警告

顺带还教了一个更重要的技能那就是debug。

尽管其实并没有出现严重的问题，只是人家帮我们改了数据，做出了一个警告而已。

```R
df <- read_csv(
  simple_csv, 
  col_types = list(x = col_double())
)
> problems(df)
# A tibble: 1 × 5
    row   col expected actual file                                                        
  <int> <int> <chr>    <chr>  <chr>                                                       
1     3     1 a double .      C:/Users/94528/AppData/Local/Temp/Rtmpq6E64E/file790475708e6
```

因为这里就已经把那个字符串的小点改为了NA了。

> 顺带一提，其实我觉得留下来也未尝不可，因为如果是稀疏矩阵这样表达反而更省事，然而这并不是稀疏矩阵的数据格式。

```r
read_csv(simple_csv, na = ".")
```

这样不仅不会报错，而且简单，而且也能识别正确数据格式。  

哦对了，这个列的类型在参数里面是这样写的呀。

```R
col_types = list(x = col_double())
```

## 列类型

1. col_logical() 和 col_double()：这两个函数用来读取逻辑值（logicals）和实数（real numbers）。它们通常很少需要用到，因为readr包通常会自动猜测数据的类型。
2. col_integer()：这个函数用来读取整数。在这本书中，我们很少区分整数和双精度浮点数（doubles），因为它们在功能上是等价的。但是，明确地读取整数有时是有用的，因为整数占用的内存是双精度浮点数的一半。
3. col_character()：这个函数用来读取字符串。当你有一个列是数字标识符时，明确指定使用这个函数是有用的。数字标识符是一长串数字，用来识别一个对象，但不适合进行数学运算。例如，电话号码、社会安全号码、信用卡号等。
4. col_factor()、col_date() 和 col_datetime()：这些函数分别用来创建因子（factors）、日期（dates）和日期时间（date-times）。我们将在第16章和第17章中更多地了解这些数据类型。
5. col_number()：这是一个宽容的数值解析器，它会忽略非数值部分，特别适用于货币。我们将在第13章中更多地了解它。
6. col_skip()：这个函数用来跳过一个列，使其不包含在结果中。如果你有一个大的CSV文件，并且你只想使用其中的一些列，使用这个函数可以加快读取数据的速度。

但是感觉写起来这些方法很好，但是没有啥逻辑，很容易就忘记了。正常的搭配在上面出现过一次了，是`list()`搭配`col_character()`使用的。

```R
another_csv <- "
x,y,z
1,2,3"

read_csv(
  another_csv,
  col_types = cols(.default = col_character())
)
```

这个就从某种意义上批量定义了，只不过是默认的吗？

```R
read_csv(
  another_csv,
  col_types = cols_only(x = col_character())
)
```

这个相当于是在一行当中实现了选择和类型，不然就要col_select函数也要搞一次了。

# 从多文件中读取数据

```R
sales_files <- c(
  "https://pos.it/r4ds-01-sales",
  "https://pos.it/r4ds-02-sales",
  "https://pos.it/r4ds-03-sales"
)
read_csv(sales_files, id = "file")
```

这个仅限于字段完全相同，仅仅包含不一样的记录的多文件吧，不然合并之后多半是会报错的。

但是会多一个字段，包含了来源文件的信息。

这里还介绍了我每次都要查的一个函数。

```R
sales_files <- list.files("data", pattern = "sales\\.csv$", full.names = TRUE)
sales_files
#> [1] "data/01-sales.csv" "data/02-sales.csv" "data/03-sales.csv"
```

读取文件夹所有文件。只不过这里好像加了一个正则表达式吗，是我从来没见过的

> 正则表达式中美元符表示以什么结束
>
> ```R
> a <- c('12a3','5b4')
> grep('4$',a)
> #[1] 2
> a <- c('12.a3','5.b4')
> grep('.',a)
> [1] 1 2
> grep('\.',a)
> 错误: '\.' is an unrecognized escape in character string (<input>:1:8)
> grep('\\.',a)
> [1] 1 2
> grep('\\.b4$',a)
> [1] 2
> grep('2.a',a)
> [1] 1
> ```
>
> 然后`\\.`才能表示一个普通的点（在R语言里面是这样的，但是python好像一个就够了）
>
> 再前面的sales就是普通的匹配字符串了。
>
> 所以是整体就是以`sales.csv`结尾的意思，并没有包含多个正则表达式的意群。
>
> 至于不加修饰的点原本就是替代任意字符的意思吧。所以还是很有意思的。那这样是不是其实也不用写这么复杂，因为.也可以代表.啊哈哈哈哈哈。不过也仅限于这里对吧。
>
> 如果是我就直接写".csv"了，反正也不会匹配到这个开头的文件，毕竟那也太怪了。

# 文件写入

```r
write_csv(table1,'tabel1.csv')
```

基本写法和baseR一样啊，前面写变量，后面写(路径/)文件名。（因为我知道后面还可以加`path`参数写上路径和文件名分开。甚至能省去`paste0`的步骤。

但是作者也说了，csv本身就是文本，进入R之后就带有变量类型了（这点和SPSS很像），再保存为CSV就又丢失了变量类型这个隐藏的重要的信息了。

建议保存为R自己的单个变量保存形式rds（别问我怎么还记得这个东西，注意和Rdata的区别）

```R
write_rds(students, "students.rds")
read_rds("students.rds")
```

再有就是介绍`arrow`包了，这个形式我记得好像是适配大数据的。

```R
library(arrow)
write_parquet(students, "students.parquet")
read_parquet("students.parquet")
```

了解的不多，在知道tidyverse之后才知道还有这么一种数据格式，并且看起来也能保存变量类型信息啊。而且既然是大数据，咱们就知道，人家的读取速度必然是很快的。R本身的数据格式在读取的时候是很吃内存的。

# 数据录入

这边介绍的是简单小型数据手动录入的方法，毕竟R并不是数据录入软件嘛，这里的数据录入也只是用来测试和探索用的吧，虽然我好像用的确实很少，因为觉得还挺麻烦的。

第一个是向量化的输入

```R
tibble(
  x = c(1,2,5),
  y = c("h","m","g"),
  z = c(0.08, 0.83, 0.60)
)
```

符合R的逻辑，但是不符合直观，你最终看到的数据框相当于这里的转置不是嘛。

```R
tribble(
  ~x, ~y, ~z,
  1, "h", 0.08,
  2, "m", 0.83,
  5, "g", 0.60
)
```

这个更符合“所见即所得”的原则对吧。tribble的意思是**tr**ansposed t**ibble** 

简单来说就是字段前加上~，每个值都用逗号分开。

---------

这里还只是Whole game呀，都已经这么多知识点了，后面不会还有更多更详细的内容吧。虽然我确实更喜欢这种循序渐进，熏陶式的学习方式呢。
