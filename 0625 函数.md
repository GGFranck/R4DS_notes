# 前言

写函数最基本的想法就是避免过多的复制粘贴，那样很麻烦，且牵一发动全身。有四大优势：

1. **给函数起一个有启发性的名称**：这意味着你给函数命名时，应该选择一个能够直观反映其功能的名称。这样做的好处是，当其他开发者阅读你的代码时，他们可以更容易地理解每个函数的作用，从而提高代码的可读性和可维护性。
2. **需求变更时只需在一个地方更新代码**：当你的代码中使用了函数，并且这些函数被多次调用时，如果需求发生变化，你只需要在函数定义的地方进行修改，而不需要在每个调用点都进行修改。这样可以减少工作量，并且降低因遗漏修改而引入错误的风险。
3. **消除复制粘贴时产生的错误**：在编程中，复制粘贴代码是一种常见的做法，但这也可能导致错误，比如在一个位置更新了变量名，但在另一个位置忘记更新。通过使用函数，你可以减少这种错误，因为变量名的更新只需要在函数定义中进行一次。
4. **便于跨项目重用工作**：当你的代码中使用了可重用的函数时，你可以在不同的项目中重复使用这些函数，而不需要每次都重新编写相同的代码。这不仅可以提高你的工作效率，还可以保持代码的一致性和质量。

到底多少次复制粘贴需要写函数呢？

据说复制粘贴超过2次就要写函数了，也就是一式三份就可以用函数替代，我觉得这样也不错。

这一章要学习三种功能的函数

1. 向量函数：向量入，向量出
2. 数据框函数：数据框入，数据框出
3. 绘制函数：数据框入，图标出

做好准备吧

```R
library(tidyverse)
library(nycflights13)
```

> 我之所以懒得写函数，主要就是记忆力不太好，并且不喜欢跳来跳去看，也可能是我没有进阶，或者看代码看的太少了。

# 向量函数

之前也说了向量函数就是给一个向量，返回一个向量的函数。下面这个函数似乎是生成了一些随机的正态分布的列，然后进行了标准化吧。

```R
df <- tibble(
  a = rnorm(5),
  b = rnorm(5),
  c = rnorm(5),
  d = rnorm(5),
)

df |> mutate(
  a = (a - min(a, na.rm = TRUE)) / 
    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),
  b = (b - min(a, na.rm = TRUE)) / 
    (max(b, na.rm = TRUE) - min(b, na.rm = TRUE)),
  c = (c - min(c, na.rm = TRUE)) / 
    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),
  d = (d - min(d, na.rm = TRUE)) / 
    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),
)
```

这样所有的列都变成了0到1的标准正态分布了。但是写起来太繁琐了，中间a要改成b改成c，一旦有一个改错了，一整列就算错了。

> 因为没有设置种子，所以结果肯定是不一样的

## 写一个函数

```R
(█ - min(█, na.rm = TRUE)) / (max(█, na.rm = TRUE) - min(█, na.rm = TRUE))
```

可以看出来mutate的每个都有相同的模式，都进行了相同的运算。

要写一个函数包括三部分内容

- 函数名
- 参数
- 主体

```R
name <- function(arguments) {
  body
}
```

这里就写成这样

```r
rescale01 <- function(x) {
  (x - min(x, na.rm = TRUE)) /
    (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
```

那么原本的函数就可以写成下面这样

```R
df %>% mutate(
  a = rescale01(a),
  b = rescale01(b),
  c = rescale01(c),
  d = rescale01(d)
)
```

如果学了第26章，则会有更简洁的写法。

```R
df %>%
  mutate(across(a:d, rescale01))
```

## 改进函数

由于要求一行代码，所以在这主体部分进行了两次计算。那么减少计算量的话， 不妨只计算一次然后保存下来，`range()`函数可以同时返回最大值和最小值。

```R
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}
```

```r
x <- c(1:10, Inf)
rescale01(x)
#>  [1]   0   0   0   0   0   0   0   0   0   0 NaN
```

当这个函数运用于带有无穷的向量，居然也能成功，只不过其他的数字都变成了0.这个时候range也得定义一下无穷的参数了。

```R
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE, finite = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}

rescale01(x)
#>  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667
#>  [8] 0.7777778 0.8888889 1.0000000       Inf
```

这样就会自动忽略缺失值和无穷的值了。到这里你就会发现，减少了不必要的代码，也能减少不必要的重复运算。

## 一些例子（变体）

**计算标准分数Z-score**

```R
z_score <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}
```

**离群值限制**

```R
clamp <- function(x, min, max) {
  case_when(
    x < min ~ min,
    x > max ~ max,
    .default = x
  )
}

clamp(1:10, min = 3, max = 7)
#>  [1] 3 3 3 4 5 6 7 7 7 7
```

**首字母大写**

```R
first_upper <- function(x) {
  str_sub(x, 1, 1) <- str_to_upper(str_sub(x, 1, 1))
  x
}

first_upper("hello")
#> [1] "Hello"
```

一个清洗数字的函数，去掉美元符和逗号，也可以去掉百分比符号

```R
# https://twitter.com/NVlabormarket/status/1571939851922198530
clean_number <- function(x) {
  is_pct <- str_detect(x, "%")
  num <- x |> 
    str_remove_all("%") |> 
    str_remove_all(",") |> 
    str_remove_all(fixed("$")) |> 
    as.numeric()
  if_else(is_pct, num / 100, num)
}

clean_number("$12,300")
#> [1] 12300
clean_number("45%")
#> [1] 0.45
```

缺失值发现

```R
fix_na <- function(x) {
  if_else(x %in% c(997, 998, 999), NA, x)
}
```

## 总结函数

有的时候设置了参数也想复制粘贴，比如合并字符串且最后一个是and连接，参数也不想多搞几遍了。

```R
commas <- function(x) {
  str_flatten(x, collapse = ", ", last = " and ")
}

commas(c("cat", "dog", "pigeon"))
#> [1] "cat, dog and pigeon"
```

或者参数保留的计算，我们可以自己把一样的参数写进自己的函数当中。比如计算变异系数。

```R
cv <- function(x, na.rm = FALSE) {
  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)
}

cv(runif(100, min = 0, max = 50))
#> [1] 0.5196276
cv(runif(100, min = 0, max = 500))
#> [1] 0.5652554
```

又或者是觉得一个常规操作名字不好记，直接写成自己熟悉的名字来调用。

```R
n_missing <- function(x) {
  sum(is.na(x))
}
n_missing(sample(c(NA, 1, 2), 100, replace = TRUE))
```

多个向量的函数。比如计算模型预测和实际值的平均误差。（可能调试模型的时候要反复调用的）

```R
# https://twitter.com/neilgcurrie/status/1571607727255834625
mape <- function(actual, predicted) {
  sum(abs((actual - predicted) / actual)) / length(actual)
}
```

----

Rstudio关于函数有两个快捷键，一个是F2查找编写函数的定义（就是放在函数上面，跳转到定义的语句），一个是ctrl+.可以模糊查找（感觉没用出来）

## 练习

> Practice turning the following code snippets into functions. Think about what each function does. What would you call it? How many arguments does it need?
>
> ```R
> mean(is.na(x))
> mean(is.na(y))
> mean(is.na(z))
> 
> x / sum(x, na.rm = TRUE)
> y / sum(y, na.rm = TRUE)
> z / sum(z, na.rm = TRUE)
> 
> round(x / sum(x, na.rm = TRUE) * 100, 1)
> round(y / sum(y, na.rm = TRUE) * 100, 1)
> round(z / sum(z, na.rm = TRUE) * 100, 1)
> ```

```R
percent_na <- function(x) {
  mean(is.na(x))
}#计算缺失值占比
prop <- function(x) {
  x / sum(x, na.rm = TRUE)
}#计算每个数据在总和中的比例
percent(1:10) <- function(x) {
  round(x / sum(x, na.rm = TRUE) * 100, 1)
}#计算每个数据在总和中的百分比（保留个位数）
```

> In the second variant of `rescale01()`, infinite values are left unchanged. Can you rewrite `rescale01()` so that `-Inf` is mapped to 0, and `Inf` is mapped to 1?

```R
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE, finite = TRUE)
  case_when(
    x == -Inf ~ 0,
    x == Inf ~ 1,
    .default = (x - rng[1]) / (rng[2] - rng[1])
  )
}
x <- c(-Inf, 1:10, Inf)
rescale01(x)
```

加个条件语句就好了吧。

> Given a vector of birthdates, write a function to compute the age in years.

诶，日期相关的我都忘记了。

```R
set.seed(1234)
birthdays <- runif(20, as.Date("2001-01-01"), as.Date("2017-12-31")) %>%
  as_date()
age <- function(x) {
  (today() - x) %>%
    as.period() %>%
    as.numeric(units = "year")
}
age(birthdays)
```

difftime类型不太好使，还得是period或者duration才可以。

> Write your own functions to compute the variance and skewness of a numeric vector. You can look up the definitions on Wikipedia or elsewhere.

写一个计算方差和偏度的函数。方差还好说，偏度是真的不知道。我敢肯定R都有对应的函数的，只是我不知道而已。

[方差公式](https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE%E5%85%AC%E5%BC%8F/3638551)百度百科提供了样本方差和母体方差。

[偏度的计算公式](https://mp.weixin.qq.com/s?__biz=MzAxMjUyNDQ5OA==&mid=2653564181&idx=1&sn=5007c011c709123003161c26cfab020c&chksm=806e03a8b7198abe07c3f715162192be89eefe91d28cebd51fc086a4fc5de0f29e587c678866&scene=27) 但是说实话我好像连这个E应该是期望都不记得了。
$$
Skew(X)=E[(\frac{X-\mu}{\sigma})^3]=\frac{EX^3-3\mu\sigma^2-\mu^3}{\sigma^3}
$$

```R
variance <- function(x) {
  sum((x - mean(x, na.rm = TRUE))^2) / (length(x) - 1)
}
skew <- function(x) {
  mean(((x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE))^3)
}
#install.packages("e1071")
library(e1071)
variance(1:10)
var(1:10)
skew(c(1, 1:6))
skewness(c(1, 1:6))
```

不过R语言的方差好像用的是样本方差，需要自由度（样本数减一）而不是样本数

也有不少别的包可以计算偏度比如e1071，fBasics

https://blog.51cto.com/u_14191/7482375

https://www.yisu.com/ask/71023961.html

另外一个和偏度经常出现但是峰度这个概念。

> Write `both_na()`, a summary function that takes two vectors of the same length and returns the number of positions that have an `NA` in both vectors.

就是一个函数，提供两个向量，相同位置都是NA就返回位置，那么这个就是向量入向量出的函数。

```R
both_na <- function(x, y) {
  if (length(x) != length(y)) {
    stop("x and y must be the same length", call. = FALSE)
  } else {
    c(1:length(x))[is.na(x) & is.na(y)]
  }
}
x <- c(1, NA, 3, NA)
y <- c(2, NA, 6)
y <- c(2, NA, 6, NA)
both_na(x, y)
```

原来error是`stop`这样的函数写出来的。

> Read the documentation to figure out what the following functions do. Why are they useful even though they are so short?
>
> ```R
> is_directory <- function(x) {
> file.info(x)$isdir
> }
> is_readable <- function(x) {
> file.access(x, 4) == 0
> }
> 
> setwd("D:/Data/知识库/R语言基础/R4DS学习笔记/0625 函数.assets")
> is_directory("./test")
> is_directory("./test/test.txt")
> file.info("./test/test.txt")
> file.access("./test/test.txt")
> ```

这个函数的作用是检查一个文件路径是否是一个目录。它使用了R语言的`file.info`函数来获取文件信息，然后返回`isdir`属性的值。如果文件路径是一个目录，则返回`TRUE`，否则返回`FALSE`。

这个函数的作用是检查一个文件路径是否可读。它使用了R语言的`file.access`函数来检查文件的访问权限，第一个参数是文件路径，第二个参数是权限模式（4表示读权限）。如果文件可读，则返回`TRUE`，否则返回`FALSE`。

> 直接问Codeium就好了。自己试一试也可以

# 数据框函数

向量函数相当于是dplyr的同级函数，如果这些函数也要重复，那么就对应的是数据框函数了。

## 直接简洁的计算

我记得aggregate函数一步到位的，但是dplyr汇总平均值就要summarise和mean联用了，有没有方法也是一步到位呢？

```r
grouped_mean <- function(df, group_var, mean_var) {
  df |> 
    group_by(group_var) |> 
    summarize(mean(mean_var))
}

diamonds |> grouped_mean(cut, carat)
#> Error in `group_by()`:
#> ! Must group by variables found in `.data`.
#> ✖ Column `group_var` is not found.
```

但是这么写会出错

```R
df <- tibble(
  mean_var = 1,
  group_var = "g",
  group = 1,
  x = 10,
  y = 100
)

df |> grouped_mean(group, x)
#> # A tibble: 1 × 2
#>   group_var `mean(mean_var)`
#>   <chr>                <dbl>
#> 1 g                        1
df |> grouped_mean(group, y)
#> # A tibble: 1 × 2
#>   group_var `mean(mean_var)`
#>   <chr>                <dbl>
#> 1 g                        1
```

查看原因，发现怎么算都是mean_var，平均值也没有算对，感觉x和y都没有算进去。据说是因为dplyr本身因为简洁的考虑，能直接在函数内部引用列名，也就是采用字面意思。但要是想要使用实际含义，这个时候就得加上两个大括号，（实际的变量）可以看看我自己写的这个例子。

```R
r$> df <- tibble(
      x = 1:3,
      y = 1:3 * (-1)
    )
r$> y <- 1
r$> df %>%
      mutate(x = y)
# A tibble: 3 x 2
      x     y
  <dbl> <dbl>
1    -1    -1
2    -2    -2
3    -3    -3
r$> df %>%
      mutate(x = {{ y }})
# A tibble: 3 x 2
      x     y
  <dbl> <dbl>
1     1    -1
2     1    -2
3     1    -3
```

那么在函数当中也是，dplyr采用了括号内的字面意思，但是在数据框内大概率是找不到这个参数名一样的列名了，这个时候就要使用数据框外部（函数的定义域内那参数也算）的实际意义。加上两个大括号，也就是拥抱一下，就可以成功了。

```R
grouped_mean <- function(df, group_var, mean_var) {
  df |> 
    group_by({{ group_var }}) |> 
    summarize(mean({{ mean_var }}))
}

df |> grouped_mean(group, x)
#> # A tibble: 1 × 2
#>   group `mean(x)`
#>   <dbl>     <dbl>
#> 1     1        10
```

成功了，这个时候tibble上面展示的就是x而不是mean_var了。

## 什么时候去拥抱{{}}

这里我有点看不懂了。

数据掩盖类：arrange，filter，summarise

整洁选择：select，relocate，rename

直觉评估

> 原来还有麻烦的方法嘛，先enquo一下，然后前面加两个感叹号强制展开
>
> ```R
> col_name <- enquo(var)
> !!col_name := !!col_name + 1
> ```
>
> 列名已知才能用=，不知道就得用rlang包的:=啊。

## 常用例子

一个数据探索性分析，一键计算6个特征值。

```R
summary6 <- function(data, var) {
  data |> summarize(
    min = min({{ var }}, na.rm = TRUE),
    mean = mean({{ var }}, na.rm = TRUE),
    median = median({{ var }}, na.rm = TRUE),
    max = max({{ var }}, na.rm = TRUE),
    n = n(),
    n_miss = sum(is.na({{ var }})),
    .groups = "drop"
  )
}

diamonds |> summary6(carat)
#> # A tibble: 1 × 6
#>     min  mean median   max     n n_miss
#>   <dbl> <dbl>  <dbl> <dbl> <int>  <int>
#> 1   0.2 0.798    0.7  5.01 53940      0
```

我记得之前医学数据实战有类似的函数。

```R
epiDisplay::summ(diamonds$carat)
```

那么summarise结合老伙计group_by，一样可以接着使用。

```R
diamonds |> 
  group_by(cut) |> 
  summary6(carat)
#> # A tibble: 5 × 7
#>   cut         min  mean median   max     n n_miss
#>   <ord>     <dbl> <dbl>  <dbl> <dbl> <int>  <int>
#> 1 Fair       0.22 1.05    1     5.01  1610      0
#> 2 Good       0.23 0.849   0.82  3.01  4906      0
#> 3 Very Good  0.2  0.806   0.71  4    12082      0
#> 4 Premium    0.2  0.892   0.86  4.01 13791      0
#> 5 Ideal      0.2  0.703   0.54  3.5  21551      0
```

```R
diamonds |> 
  group_by(cut) |> 
  summary6(log10(carat))
#> # A tibble: 5 × 7
#>   cut          min    mean  median   max     n n_miss
#>   <ord>      <dbl>   <dbl>   <dbl> <dbl> <int>  <int>
#> 1 Fair      -0.658 -0.0273  0      0.700  1610      0
#> 2 Good      -0.638 -0.133  -0.0862 0.479  4906      0
#> 3 Very Good -0.699 -0.164  -0.149  0.602 12082      0
#> 4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0
#> 5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0
```

计算后的变量也是可以带入的，这个怎么理解，那么相当于是`var=log(carat)`由于不是字面意思，那传入内部计算的就是对数话的carat列。

那同时计算多个变量，就可以用后面会学习到的`across()`函数。我试试好吧，这里我还是不太会用啊。

--------

另外一个例子，不仅计数，同时还计算构成比

```R
# https://twitter.com/Diabb6/status/1571635146658402309
count_prop <- function(df, var, sort = FALSE) {
  df |>
    count({{ var }}, sort = sort) |>
    mutate(prop = n / sum(n))
}

diamonds |> count_prop(clarity)
#> # A tibble: 8 × 3
#>   clarity     n   prop
#>   <ord>   <int>  <dbl>
#> 1 I1        741 0.0137
#> 2 SI2      9194 0.170 
#> 3 SI1     13065 0.242 
#> 4 VS2     12258 0.227 
#> 5 VS1      8171 0.151 
#> 6 VVS2     5066 0.0939
#> # ℹ 2 more rows
```

----

找到一列变量唯一排序的展示，并且还能提供一个条件

```R
unique_where <- function(df, condition, var) {
  df |> 
    filter({{ condition }}) |> 
    distinct({{ var }}) |> 
    arrange({{ var }})
}

# Find all the destinations in December
flights |> unique_where(month == 12, dest)
#> # A tibble: 96 × 1
#>   dest 
#>   <chr>
#> 1 ABQ  
#> 2 ALB  
#> 3 ATL  
#> 4 AUS  
#> 5 AVL  
#> 6 BDL  
#> # ℹ 90 more rows
```

-------

一种类似于冻结窗格的函数

```R
subset_flights <- function(rows, cols) {
  flights %>%
    filter({{ rows }}) %>%
    dplyr::select(time_hour, carrier, flight, {{ cols }})
}
subset_flights(month == 12, dep_delay)
```

注意，这个函数不用传递flights数据框，并且我似乎好像一些包冲突了，不得不在select报错这里指定是dplyr的select。

## 数据屏蔽与整洁选择

说实话我到现在还不理解。

```R
count_missing <- function(df, group_vars, x_var) {
  df |> 
    group_by({{ group_vars }}) |> 
    summarize(
      n_miss = sum(is.na({{ x_var }})),
      .groups = "drop"
    )
}

flights |> 
  count_missing(c(year, month, day), dep_time)
#> Error in `group_by()`:
#> ℹ In argument: `c(year, month, day)`.
#> Caused by error:
#> ! `c(year, month, day)` must be size 336776 or 1, not 1010328.
```

直接这么写会报错。据说group_by是数据屏蔽，不是整洁选择。这个时候就要在函数里面加上`pick()`函数解决这个问题。

```R
count_missing <- function(df, group_vars, x_var) {
  df |> 
    group_by(pick({{ group_vars }})) |> 
    summarize(
      n_miss = sum(is.na({{ x_var }})),
      .groups = "drop"
  )
}

flights |> 
  count_missing(c(year, month, day), dep_time)
#> # A tibble: 365 × 4
#>    year month   day n_miss
#>   <int> <int> <int>  <int>
#> 1  2013     1     1      4
#> 2  2013     1     2      8
#> 3  2013     1     3     10
#> 4  2013     1     4      6
#> 5  2013     1     5      3
#> 6  2013     1     6      1
#> # ℹ 359 more rows
```

莫非这个pick相当于可以把向量放进去用来批量选择的时候，有点类似于python那种不设置上限的参数，但是这里相差的也有点大。

> pick函数本身也不是只能用于function里面啊
>
> 我暂时的理解就是当好多列要放进去的时候，那就得多加个pick。

## 练习

用flights数据写多个函数。

```R
filter_severe <- function(df) {
  df %>%
    filter(is.na(arr_time) | dep_delay > 60)
}
flights |> filter_severe()
summarize_severe <- function(df) {
  df %>%
    summarise(
      severe = sum(is.na(arr_time) | dep_delay > 60)
    )
}
flights |>
  group_by(dest) |>
  summarize_severe()

filter_severe <- function(df, hours) {
  df %>%
    filter(is.na(arr_time) | dep_delay > hours * 60)
}
flights |> filter_severe(hours = 2)

summarize_weather <- function(df, var) {
  df %>%
    summarise(
      min = min({{ var }}, na.rm = TRUE),
      mean = mean({{ var }}, na.rm = TRUE),
      max = max({{ var }}, na.rm = TRUE),
    )
}
weather |> summarize_weather(temp)

standardize_time <- function(df, var) {
  df %>%
    mutate({{ var }} := {{ var }} %% 100 / 60 + {{ var }} %/% 100)
}
flights |> standardize_time(sched_dep_time)
```

别的都好说，就是最后一个，要是原本的列在等号左边，居然还要加个冒号，但是这个语法我好像不知道。其实我知道，但是这个不是data.table的语法吗

查看文档，看看这些函数是数据掩盖还是整洁选择

`distinct()` data-masking

`count()` data-masking

 `group_by()` 应该也是，但是文档里面好像没写

 `rename_with()` tidy_select

 `slice_min()` 都有啊，那应该还是d，但是by参数是t

 `slice_sample()` 同理

修改下面这个函数使其泛化，任意数量的变量都可以计算。

```R
count_prop <- function(df, var, sort = FALSE) {
  df |>
    count({{ var }}, sort = sort) |>
    mutate(prop = n / sum(n))
}

count_prop <- function(df, var, sort = FALSE) {
  df |>
    count(pick({{ var }}), sort = sort) |>
    mutate(prop = n / sum(n))
}
flights %>% count_prop(c(carrier, origin))
```

加个pick就完事了。

# 绘图函数

> 我觉得写函数对于R包来说应该是很有用的，R包说实话其实就是封装好的外部函数呀。

有的时候我们画图可能也就是修改一点点的参数，很多参数都是不怎么动的。aes也是数据掩盖函数。

```R
diamonds |> 
  ggplot(aes(x = carat)) +
  geom_histogram(binwidth = 0.1)

diamonds |> 
  ggplot(aes(x = carat)) +
  geom_histogram(binwidth = 0.05)
```

太繁琐了，封装一下，需要注意的是aes也是直接拿来内部的列（相比于base），所以也需要拥抱一下。

```R
histogram <- function(df, var, binwidth = NULL) {
  df |> 
    ggplot(aes(x = {{ var }})) + 
    geom_histogram(binwidth = binwidth)
}

diamonds |> histogram(carat, 0.1)
```

![A histogram of carats of diamonds, ranging from 0 to 5, showing a unimodal, right-skewed distribution with a peak between 0 to 1 carats.](<./0625 函数.assets/unnamed-chunk-44-1.png>)

并且后面仍然是能用加号继续连接下去。

```R
diamonds |> 
  histogram(carat, 0.1) +
  labs(x = "Size (in carats)", y = "Number of diamonds")
```

我们自己写的函数就完美地融入了ggplot的体系了。

## 更多的变量

这一个小节应该也是一堆例子，比如一键绘制散点图和拟合线。

```R
# https://twitter.com/tyler_js_smith/status/1574377116988104704
linearity_check <- function(df, x, y) {
  df |>
    ggplot(aes(x = {{ x }}, y = {{ y }})) +
    geom_point() +
    geom_smooth(method = "loess", formula = y ~ x, color = "red", se = FALSE) +
    geom_smooth(method = "lm", formula = y ~ x, color = "blue", se = FALSE) 
}

starwars |> 
  filter(mass < 1000) |> 
  linearity_check(mass, height)
```

![Scatterplot of height vs. mass of StarWars characters showing a positive relationship. A smooth curve of the relationship is plotted in red, and the best fit line is ploted in blue.](<./0625 函数.assets/unnamed-chunk-46-1.png>)

---------

二维散点重叠用的六边形图

```R
hex_plot <- function(df, x, y, z, bins = 20, fun = "mean") {
  df %>%
    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) +
    stat_summary_hex(
      aes(color = after_scale(fill)), # 让fill和scale一样的颜色
      bins = bins,
      fun = fun
    )
}
diamonds %>% hex_plot(carat, price, depth)
```

![Hex plot of price vs. carat of diamonds showing a positive relationship. There are more diamonds that are less than 2 carats than more than 2 carats.](<./0625 函数.assets/unnamed-chunk-47-1.png>)

## 绘图与其他函数联用

有的时候ggplot前面就是tidyverse处理之后的数据框对吧。

```R
sorted_bars <- function(df, var) {
  df |> 
    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |>
    ggplot(aes(y = {{ var }})) +
    geom_bar()
}

diamonds |> sorted_bars(clarity)
```

![Bar plot of clarify of diamonds, where clarity is on the y-axis and counts are on the x-axis, and the bars are ordered in order of frequency: SI1, VS2, SI2, VS1, VVS2, VVS1, IF, I1.](<./0625 函数.assets/unnamed-chunk-48-1.png>)

不得不说，这个是对我启发很大，我之前也画过，但是没有这么简洁。先是回顾了fct一系列的函数，然后直接设置y就可以横向了，不需要后面再`coord_flip`了

到这里才是第一次解释新的运算符，一个冒号后面接一个等号，叫做海象运算符，因为长得像海象`:=`

> python居然是3.8才有的特性。

数据子集的（分类变量）频数柱状图。

```R
conditional_bars <- function(df, condition, var) {
  df |> 
    filter({{ condition }}) |> 
    ggplot(aes(x = {{ var }})) + 
    geom_bar()
}

diamonds |> conditional_bars(cut == "Good", clarity)
```

![Bar plot of clarity of diamonds. The most common is SI1, then SI2, then VS2, then VS1, then VVS2, then VVS1, then I1, then lastly IF.](<./0625 函数.assets/unnamed-chunk-49-1.png>)

## 标签

其实这一个小节实现的是这么样一个功能，就是把参数实际值放进函数内的字符串当中。之前用的是`str_glue()`函数，但是这里就不得不使用`rlang::englue()`函数，不然就会遇到这样的情况

```R
r$> a <- "wow"
r$> str_glue("hello {a}")
hello wow
r$> str_glue("hello {{a}}")
hello {a}
```

`rlang::englue()`就可以做到

```R
histogram <- function(df, var, binwidth) {
  label <- rlang::englue("A histogram of {{var}} with binwidth {binwidth}")
  
  df |> 
    ggplot(aes(x = {{ var }})) + 
    geom_histogram(binwidth = binwidth) + 
    labs(title = label)
}

diamonds |> histogram(carat, 0.1)
```

![Histogram of carats of diamonds, ranging from 0 to 5. The distribution is unimodal and right skewed with a peak between 0 to 1 carats.](<./0625 函数.assets/unnamed-chunk-51-1.png>)

## 练习

> Build up a rich plotting function by incrementally implementing each of the steps below:
>
> 1. Draw a scatterplot given dataset and `x` and `y` variables.
> 2. Add a line of best fit (i.e. a linear model with no standard errors).
> 3. Add a title.

就是不断精进一个画散点图的简化函数。

```R
diamonds
xy_scatter <- function(df, x, y) {
  label <- rlang::englue("A scatter plot of {{x}} vs. {{y}}")
  df %>%
    ggplot(aes(x = {{ x }}, y = {{ y }})) +
    geom_point() +
    geom_smooth(se = FALSE)
}
diamonds %>% xy_scatter(carat, price)
```

基本上就是这么写， 虽然我没怎么写，主要都是AI生成的。

![xy散点图](<./0625 函数.assets/xy散点图.png>)

# 风格

对于人类而言，简单，清晰，易懂的函数名是非常理想的，但是实际上是比较难以兼顾的。但实际上对于有自动补全功能的编辑器而言，长一点其实没有什么不好的。

通常而言，函数名最好是动词，参数最好是名词。

除非是大家都很熟知的比如`mean()`其实是`compute_mean()` ，`coef()`其实是获取系数

```R
# Too short
f()

# Not a verb, or descriptive
my_awesome_function()

# Long, but clear
impute_missing()
collapse_years()
```

然后关于大括号内的缩进，R虽然不会太在意，但是一般建议是2格。这个在VS code里面就很明显，不把4格专门设置为2格，就会在Prettier里面一直蓝色警示。

```R
# Missing extra two spaces
density <- function(color, facets, binwidth = 0.1) {
diamonds |> 
  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +
  geom_freqpoly(binwidth = binwidth) +
  facet_wrap(vars({{ facets }}))
}

# Pipe indented incorrectly
density <- function(color, facets, binwidth = 0.1) {
  diamonds |> 
  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +
  geom_freqpoly(binwidth = binwidth) +
  facet_wrap(vars({{ facets }}))
}
```

## 练习

给下面的函数想名字

```R
f1 <- function(string, prefix) {
  str_sub(string, 1, str_length(prefix)) == prefix
}

f3 <- function(x, y) {
  rep(y, length.out = length(x))
}
```

第一个函数是判断前缀匹配不匹配的函数吧。或者说开头对上了都可以。类似于`starts_with()`，但是这个只能在filter里面用好像。不如就叫`match_prefix()`

第二个函数还蛮奇怪的，取向量x的长度作为y的重复次数。就叫`rep_vector()`好了。

# 总结

这一章其实还是练习为主，介绍的概念其实也不是很多。但是细节比如拥抱，englue，不过这些在base里面肯定是不会遇到的。果然还是tidy风格的一种妥协啊。但是这个只能说是丢小芝麻拣大西瓜的办法。

这章更多的是提供了很多例子来启发咱们。但是实际上无非是实现某种目的。

之前不是对数据掩盖和整洁选择的含义有不理解吗。这里就给出了出处

[programming with dplyr](https://dplyr.tidyverse.org/articles/programming.html)

[programming with tidyr](https://tidyr.tidyverse.org/articles/programming.html)

[Programming with ggplot2](https://ggplot2-book.org/programming.html)

[What is data-masking and why do I need {{?](https://rlang.r-lib.org/reference/topic-data-mask.html) 这个是rlang的

[tidyverse style guide](https://style.tidyverse.org/functions) 这个则是函数的风格指南

但是暂时我没有兴趣看这些了，还是先多用用，遇到问题再看吧。
